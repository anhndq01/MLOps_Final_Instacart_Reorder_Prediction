{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061e355e-115e-4e19-8fc7-8ce2f283d61c",
   "metadata": {},
   "source": [
    "# 0) Imports & versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee2553f-fda8-45b3-9357-22e21224814f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidently: 0.4.40\n"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h2o\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, classification_report,\n",
    "    confusion_matrix, brier_score_loss\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "try:\n",
    "    import evidently\n",
    "    from evidently.report import Report\n",
    "    from evidently import metrics as evm\n",
    "    # handle 0.4.x vs 0.7.x naming\n",
    "    DatasetDriftMetric  = getattr(evm, \"DatasetDriftMetric\", None)\n",
    "    DatasetMissingValuesMetric = getattr(evm, \"DatasetMissingValuesMetric\", None)\n",
    "    ColumnSummaryMetric = getattr(evm, \"ColumnSummaryMetric\", None)\n",
    "    BinaryClassificationQualityMetric = (\n",
    "        getattr(evm, \"BinaryClassificationQualityMetric\", None)\n",
    "        or getattr(evm, \"ClassificationPerformanceMetric\", None)\n",
    "    )\n",
    "    print(\"Evidently:\", getattr(evidently, \"__version__\", \"(unknown)\"))\n",
    "except Exception as e:\n",
    "    DatasetDriftMetric = DatasetMissingValuesMetric = ColumnSummaryMetric = BinaryClassificationQualityMetric = None\n",
    "    print(\"Evidently not available -> reports will be skipped:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9cf984-6a05-4b43-8d3d-f865328e9d84",
   "metadata": {},
   "source": [
    "# 1) Configuration (paths, IDs, dtypes, sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40bdde79-f47a-48e5-8798-c6ff146ef18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ROOT        = \"/home/cc/MLOps/MLOps_Final_Instacart_Reorder_Prediction-main\"\n",
    "PATH_TRAIN  = f\"{ROOT}/train_data.csv\"   # processed CSVs from your 02 notebook\n",
    "PATH_TEST   = f\"{ROOT}/test_data.csv\"\n",
    "\n",
    "MODEL_ID    = \"XGBoost_3_AutoML_1_20250820_184414\"  # your screenshot / cluster id\n",
    "TARGET_COL  = \"reordered\"\n",
    "ID_COL      = \"order_id\"\n",
    "CATEGORICAL_FORCE = [\"aisle_id\", \"department_id\", TARGET_COL]  # treated as H2O factors\n",
    "\n",
    "# keep notebook responsive; raise/remove once stable\n",
    "REF_MAX = 300_000\n",
    "CUR_MAX = 200_000\n",
    "\n",
    "# engineered feature names used in training\n",
    "ENGINEERED = [\n",
    "    \"times_bought_by_user\",\n",
    "    \"avg_user_product_position\",\n",
    "    \"last_order_number\",\n",
    "    \"num_orders\",\n",
    "    \"avg_days_since_prior_order\",\n",
    "    \"num_items\",\n",
    "    \"user_reorder_prop\",\n",
    "    \"product_total_orders\",\n",
    "    \"product_reorder_prop\",\n",
    "    \"avg_add_to_cart_order\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2bf118-6d0d-4f88-84ac-caa83571f258",
   "metadata": {},
   "source": [
    "# 2) H2O: attach to cluster and fetch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcab70d0-b751-4e07-b66c-51e81f73cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54329. connected.\n",
      "Warning: Your H2O cluster version is (4 months and 24 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>19 hours 48 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>4 months and 24 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_cc_19f0xo</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.702 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>48</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>48</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54329</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.10 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         19 hours 48 mins\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.7\n",
       "H2O_cluster_version_age:    4 months and 24 days\n",
       "H2O_cluster_name:           H2O_from_python_cc_19f0xo\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.702 Gb\n",
       "H2O_cluster_total_cores:    48\n",
       "H2O_cluster_allowed_cores:  48\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54329\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.10 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O server: 3.46.0.7\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import h2o\n",
    "    h2o.cluster().shutdown(prompt=False)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import h2o\n",
    "h2o.init(ip=\"localhost\", port=54329, start_h2o=True, nthreads=-1, max_mem_size=\"8G\")\n",
    "print(\"H2O server:\", h2o.cluster().version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f48009c-bcae-4c90-a6ca-156414b43473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in cluster: XGBoost_3_AutoML_1_20250820_184414\n"
     ]
    }
   ],
   "source": [
    "import os, h2o\n",
    "MODEL_ID = os.path.basename(\"/home/cc/MLOps/MLOps_Final_Instacart_Reorder_Prediction-main/models/XGBoost_3_AutoML_1_20250820_184414\")\n",
    "\n",
    "try:\n",
    "    model = h2o.get_model(MODEL_ID)   \n",
    "    print(\"Found in cluster:\", model.model_id)\n",
    "except Exception:\n",
    "    model = None\n",
    "    print(\"Model not present in this H2O session:\", MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faf4d83-70d7-4a0b-afd2-331efa2b3702",
   "metadata": {},
   "source": [
    "# 3) Data loading helpers (sample to keep memory in check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5475a6f-3624-43d7-ae28-cf1fe6c3da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_df(path, n=None):\n",
    "    df = pd.read_csv(path)\n",
    "    if n is not None and len(df) > n:\n",
    "        df = df.sample(n, random_state=42).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def ensure_object_cats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # stringify potential categoricals\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\"):\n",
    "            df[c] = df[c].astype(str)\n",
    "    for c in CATEGORICAL_FORCE:\n",
    "        if c in df.columns and df[c].dtype != \"object\":\n",
    "            df[c] = df[c].astype(str)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb41f035-67c5-4493-8d91-695ee2026fb1",
   "metadata": {},
   "source": [
    "# 4) Load processed train/test (from 02_Data_Preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0184abd4-b733-4d6e-82a1-fe8dfd0a0c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames: (300000, 24) (200000, 24)\n"
     ]
    }
   ],
   "source": [
    "assert os.path.exists(PATH_TRAIN) and os.path.exists(PATH_TEST), \"Processed train/test CSVs not found.\"\n",
    "ref_full = load_df(PATH_TRAIN, REF_MAX)\n",
    "cur_full = load_df(PATH_TEST,  CUR_MAX)\n",
    "\n",
    "# drop extras to match your modeling notebook\n",
    "for df in (ref_full, cur_full):\n",
    "    df.drop(columns=[\"Unnamed: 0\", \"product_name\"], errors=\"ignore\", inplace=True)\n",
    "    # IMPORTANT: keep 'aisle_id' & 'department_id' (categoricals) and the ENGINEERED cols\n",
    "    # Any missing engineered cols -> create (rare if CSVs are the latest)\n",
    "    for c in ENGINEERED:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "\n",
    "ref_full = ensure_object_cats(ref_full)\n",
    "cur_full = ensure_object_cats(cur_full)\n",
    "\n",
    "print(\"Frames:\", ref_full.shape, cur_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d08626-2927-46c3-a774-c716abf7ed03",
   "metadata": {},
   "source": [
    "# 5) Model schema alignment (NO target column inside features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "995de8c3-24a4-40ed-8420-f7b0afa2eb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing vs model (train): []\n",
      "Missing vs model (test) : []\n"
     ]
    }
   ],
   "source": [
    "def expected_features_no_target(h2o_model, target=TARGET_COL):\n",
    "    out = h2o_model._model_json.get(\"output\", {}) or {}\n",
    "    names = out.get(\"names\", []) or []\n",
    "    resp  = out.get(\"response_column_name\", None)\n",
    "    drop = {target, resp, \"predict\", \"p0\", \"p1\", None}\n",
    "    return [c for c in names if c not in drop]\n",
    "\n",
    "def coerce_to_expected(df: pd.DataFrame, exp_cols, cat_cols=(\"aisle_id\",\"department_id\")) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]  # normalize names\n",
    "    # add any missing expected columns (cats -> '0', nums -> 0.0)\n",
    "    missing = [c for c in exp_cols if c not in df.columns]\n",
    "    for c in missing:\n",
    "        if c in cat_cols:\n",
    "            df[c] = \"0\"\n",
    "        else:\n",
    "            df[c] = 0.0\n",
    "    # order strictly to expected features (target kept outside)\n",
    "    return df[exp_cols + [c for c in df.columns if c not in exp_cols]]\n",
    "\n",
    "def median_fill_expected(train_df: pd.DataFrame, test_df: pd.DataFrame, exp_cols, cat_cols=(\"aisle_id\",\"department_id\")):\n",
    "    num_exp = [c for c in exp_cols if c not in cat_cols]\n",
    "    med = pd.to_numeric(train_df[num_exp].stack(), errors=\"coerce\").groupby(level=1).median()\n",
    "    for c in num_exp:\n",
    "        train_df[c] = pd.to_numeric(train_df[c], errors=\"coerce\").fillna(med.get(c, 0.0))\n",
    "        test_df[c]  = pd.to_numeric(test_df[c],  errors=\"coerce\").fillna(med.get(c, 0.0))\n",
    "    return train_df, test_df\n",
    "\n",
    "exp = expected_features_no_target(model)  # <-- no target column here\n",
    "ref_full = coerce_to_expected(ref_full, exp)\n",
    "cur_full = coerce_to_expected(cur_full, exp)\n",
    "ref_full, cur_full = median_fill_expected(ref_full, cur_full, exp)\n",
    "\n",
    "print(\"Missing vs model (train):\", [c for c in exp if c not in ref_full.columns])\n",
    "print(\"Missing vs model (test) :\", [c for c in exp if c not in cur_full.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb017912-9746-47de-9d7e-387a5448eba6",
   "metadata": {},
   "source": [
    "# 6) Scoring (features only), metrics at fixed threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc29ea26-c9c7-4aac-8f37-06493d1c1c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "Export File progress: |██████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "Export File progress: |██████████████████████████████████████████████████████████| (done) 100%\n",
      "REF  -> AUC: 0.4689 | PR-AUC: 0.5673 | Brier: 0.5892\n",
      "CUR  -> AUC: 0.4648 | PR-AUC: 0.5737 | Brier: 0.5984\n",
      "\n",
      "REF @thr report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4107    1.0000    0.5823    123218\n",
      "           1     0.0000    0.0000    0.0000    176782\n",
      "\n",
      "    accuracy                         0.4107    300000\n",
      "   macro avg     0.2054    0.5000    0.2911    300000\n",
      "weighted avg     0.1687    0.4107    0.2392    300000\n",
      "\n",
      "\n",
      "CUR @thr report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4015    1.0000    0.5730     80302\n",
      "           1     0.0000    0.0000    0.0000    119698\n",
      "\n",
      "    accuracy                         0.4015    200000\n",
      "   macro avg     0.2008    0.5000    0.2865    200000\n",
      "weighted avg     0.1612    0.4015    0.2301    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FIXED_THRESHOLD = 0.5\n",
    "\n",
    "def enforce_factor_cols(hf, cols):\n",
    "    for c in cols:\n",
    "        if c in hf.columns:\n",
    "            hf[c] = hf[c].asfactor()\n",
    "\n",
    "def score_and_metrics_features(df_features: pd.DataFrame, df_with_target: pd.DataFrame, h2o_model, threshold=0.7448951904827723):\n",
    "    # H2OFrame with FEATURES ONLY (prevents duplicate target parsing)\n",
    "    hf = h2o.H2OFrame(df_features[exp])\n",
    "    enforce_factor_cols(hf, CATEGORICAL_FORCE)\n",
    "\n",
    "    pred = h2o_model.predict(hf).as_data_frame(use_multi_thread=True)\n",
    "    p1   = pred[\"p1\"].values if \"p1\" in pred.columns else pred.iloc[:, -1].values\n",
    "\n",
    "    y = (df_with_target[TARGET_COL].astype(str).values == \"1\").astype(int)\n",
    "    yhat = (p1 >= threshold).astype(int)\n",
    "\n",
    "    scored = pd.DataFrame(index=df_with_target.index)\n",
    "    if ID_COL in df_with_target.columns:\n",
    "        scored[ID_COL] = df_with_target[ID_COL].values\n",
    "    scored[\"proba\"]    = p1\n",
    "    scored[\"y_pred\"]   = yhat\n",
    "    scored[TARGET_COL] = y\n",
    "\n",
    "    metrics = dict(\n",
    "        auc   = roc_auc_score(y, p1),\n",
    "        ap    = average_precision_score(y, p1),\n",
    "        brier = brier_score_loss(y, p1),\n",
    "        report= classification_report(y, yhat, digits=4),\n",
    "        cm    = confusion_matrix(y, yhat),\n",
    "    )\n",
    "    return scored, metrics\n",
    "\n",
    "# We need the target column alongside features for metrics.\n",
    "# Your processed CSVs include TARGET_COL; we align dataframes by index:\n",
    "ref_with_target = load_df(PATH_TRAIN, REF_MAX)\n",
    "cur_with_target = load_df(PATH_TEST,  CUR_MAX)\n",
    "for df in (ref_with_target, cur_with_target):\n",
    "    df = df  # (placeholder to keep structure similar)\n",
    "    # ensure target dtype consistent\n",
    "    if TARGET_COL in df.columns and df[TARGET_COL].dtype != \"object\":\n",
    "        df[TARGET_COL] = df[TARGET_COL].astype(int)\n",
    "\n",
    "ref_scored, m_ref = score_and_metrics_features(ref_full, ref_with_target, model, FIXED_THRESHOLD)\n",
    "cur_scored, m_cur = score_and_metrics_features(cur_full, cur_with_target, model, FIXED_THRESHOLD)\n",
    "\n",
    "print(\"REF  -> AUC: %.4f | PR-AUC: %.4f | Brier: %.4f\" % (m_ref[\"auc\"], m_ref[\"ap\"], m_ref[\"brier\"]))\n",
    "print(\"CUR  -> AUC: %.4f | PR-AUC: %.4f | Brier: %.4f\" % (m_cur[\"auc\"], m_cur[\"ap\"], m_cur[\"brier\"]))\n",
    "print(\"\\nREF @thr report:\\n\", m_ref[\"report\"])\n",
    "print(\"\\nCUR @thr report:\\n\", m_cur[\"report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9d196-d727-46df-bdc4-c0574f3103da",
   "metadata": {},
   "source": [
    "# 7) Evidently reports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a691824a-e6a6-4dbe-8d1f-6cdab99bfead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/jlenv/lib/python3.8/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "/home/cc/jlenv/lib/python3.8/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "/home/cc/jlenv/lib/python3.8/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "/home/cc/jlenv/lib/python3.8/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: baseline_vs_test.html\n"
     ]
    }
   ],
   "source": [
    "def build_report(ref_df, cur_df, out_html):\n",
    "    if not (Report and (DatasetDriftMetric or DatasetMissingValuesMetric)):\n",
    "        print(\"Evidently is not installed/compatible; skipping report.\")\n",
    "        return\n",
    "    metrics = []\n",
    "    if DatasetDriftMetric:          metrics.append(DatasetDriftMetric())\n",
    "    if DatasetMissingValuesMetric:  metrics.append(DatasetMissingValuesMetric())\n",
    "    if ColumnSummaryMetric:         metrics.append(ColumnSummaryMetric(column_name=\"proba\"))\n",
    "    if BinaryClassificationQualityMetric:\n",
    "        # some versions want 'prediction' (pred label), others support proba via params\n",
    "        metrics.append(BinaryClassificationQualityMetric(target=TARGET_COL, prediction=\"y_pred\"))\n",
    "    rep = Report(metrics=metrics)\n",
    "    rep.run(reference_data=ref_df, current_data=cur_df)\n",
    "    rep.save_html(out_html)\n",
    "    print(\"Saved:\", out_html)\n",
    "\n",
    "build_report(ref_scored, cur_scored, \"baseline_vs_test.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43aad8b-ef32-41f7-a7f5-74dd76539376",
   "metadata": {},
   "source": [
    "# 8) \"Changed\" test: tweak 2 features & re-monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "844b571b-0b6e-4ef5-a032-185fab7d857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "Export File progress: |██████████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      "CHGD -> AUC: 0.4613 | PR-AUC: 0.5700 | Brier: 0.5984\n",
      "\n",
      "CHGD @thr report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4015    1.0000    0.5730     80302\n",
      "           1     0.0000    0.0000    0.0000    119698\n",
      "\n",
      "    accuracy                         0.4015    200000\n",
      "   macro avg     0.2008    0.5000    0.2865    200000\n",
      "weighted avg     0.1612    0.4015    0.2301    200000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/jlenv/lib/python3.8/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "/home/cc/jlenv/lib/python3.8/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "/home/cc/jlenv/lib/python3.8/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "/home/cc/jlenv/lib/python3.8/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: baseline_vs_changed.html\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "\n",
    "# =========================================================\n",
    "changed = cur_full.copy()\n",
    "if \"order_hour_of_day\" in load_df(PATH_TEST, 5).columns:  # peek columns safely\n",
    "    # shift hour by +4 modulo 24 if present\n",
    "    base = load_df(PATH_TEST, CUR_MAX)\n",
    "    if \"order_hour_of_day\" in base.columns:\n",
    "        hours = pd.to_numeric(base[\"order_hour_of_day\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "        base[\"order_hour_of_day\"] = (hours + 4) % 24\n",
    "        # reflect into 'changed' if that feature is in exp (it usually isn't), safe no-op otherwise\n",
    "\n",
    "# second tweak: bump user-product frequency by +2 (if present)\n",
    "if \"times_bought_by_user\" in changed.columns:\n",
    "    changed[\"times_bought_by_user\"] = pd.to_numeric(changed[\"times_bought_by_user\"], errors=\"coerce\").fillna(0) + 2\n",
    "\n",
    "chg_with_target = load_df(PATH_TEST, CUR_MAX)\n",
    "chg_scored, m_chg = score_and_metrics_features(changed, chg_with_target, model, FIXED_THRESHOLD)\n",
    "print(\"\\nCHGD -> AUC: %.4f | PR-AUC: %.4f | Brier: %.4f\" % (m_chg[\"auc\"], m_chg[\"ap\"], m_chg[\"brier\"]))\n",
    "print(\"\\nCHGD @thr report:\\n\", m_chg[\"report\"])\n",
    "build_report(ref_scored, chg_scored, \"baseline_vs_changed.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
