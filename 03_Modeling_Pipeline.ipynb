{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744641bb-82f7-44ea-92e9-5f54a10134f0",
   "metadata": {},
   "source": [
    "# Modeling Pipeline and AutoML\n",
    "## Load data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51fd49f4-c54f-4af5-a893-fc8add6671df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424f3910-af70-441f-bf90-4238f3ff88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/processed/train_data.csv')\n",
    "test_data  = pd.read_csv('data/processed/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed56d1a-4225-4120-8a97-6a660d38b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns = ['Unnamed: 0','product_name'])\n",
    "test_data = test_data.drop(columns = ['Unnamed: 0','product_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8be0192-80bc-411f-a5ea-d477618bfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['reordered','product_id','user_id'])\n",
    "y_train = train_data['reordered']\n",
    "\n",
    "X_test  = test_data.drop(columns=['reordered','product_id','user_id'])\n",
    "y_test  = test_data['reordered']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c72ab-864c-4b27-939d-a836fad56ead",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d15cbf32-a3fc-4acb-96cc-7948c4f66732",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['aisle_id', 'department_id']\n",
    "numeric_cols = [col for col in X_train.columns if col not in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c4c28d7-3920-4470-a214-7b94cde826c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ee8aa-42b0-4699-8c10-95ec1ef010e2",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Since our model is trying to predict `reordered`, which is a binary variable, we will choose F1 score as our main metrics, which balances between precision and recall. We will also look at accuracy as well.\n",
    "\n",
    "### Baseline Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c7a3c2-8a6b-4b58-b9f6-8a8cb97487ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=32021))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ba07c2-9018-4fd0-9060-fd4ec6d83292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 23:53:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/18 23:53:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF logged.\n"
     ]
    }
   ],
   "source": [
    "# Log baseline results with MLFlow\n",
    "with mlflow.start_run(run_name='Baseline_RandomForest'):\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "    y_pred = rf_pipeline.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_param('Model', 'RandomForest')\n",
    "    mlflow.log_metric('f1_score', f1)\n",
    "    mlflow.log_metric('accuracy', accuracy)\n",
    "    mlflow.sklearn.log_model(rf_pipeline, 'baseline_rf_pipeline')\n",
    "\n",
    "    # Confusion matrix plot\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_title('Confusion Matrix for Baseline RandomForest')\n",
    "    cm_path = 'confusion_matrix_rf.png'\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close(fig)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    \n",
    "print('Baseline RF logged.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce77b1e-17ec-41c1-86fd-3aa552b4b7d9",
   "metadata": {},
   "source": [
    "### H2O AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac5a5874-c360-4446-863d-312f01027b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"13\" 2019-09-17; Java(TM) SE Runtime Environment (build 13+33); Java HotSpot(TM) 64-Bit Server VM (build 13+33, mixed mode, sharing)\n",
      "  Starting server from /opt/anaconda3/envs/MLOps/lib/python3.13/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/kf/8ms7_h8j11bf86d6c5ykldrw0000gn/T/tmpf5xrsdms\n",
      "  JVM stdout: /var/folders/kf/8ms7_h8j11bf86d6c5ykldrw0000gn/T/tmpf5xrsdms/h2o_quynhanhnd2402_started_from_python.out\n",
      "  JVM stderr: /var/folders/kf/8ms7_h8j11bf86d6c5ykldrw0000gn/T/tmpf5xrsdms/h2o_quynhanhnd2402_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      " successful.o H2O server at http://127.0.0.1:54321 ...\n",
      "Warning: Your H2O cluster version is (4 months and 22 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>4 months and 22 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_quynhanhnd2402_ct59tv</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>2 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.13.5 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------------\n",
       "H2O_cluster_uptime:         03 secs\n",
       "H2O_cluster_timezone:       America/Chicago\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.7\n",
       "H2O_cluster_version_age:    4 months and 22 days\n",
       "H2O_cluster_name:           H2O_from_python_quynhanhnd2402_ct59tv\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    2 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.13.5 final\n",
       "--------------------------  -------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bec0b7f-2b94-40c8-9fa5-e9a2f0c0a8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "train_h2o = h2o.H2OFrame(pd.concat([X_train, y_train], axis=1))\n",
    "test_h2o  = h2o.H2OFrame(pd.concat([X_test, y_test], axis=1))\n",
    "\n",
    "train_h2o['reordered'] = train_h2o['reordered'].asfactor()\n",
    "test_h2o['reordered']  = test_h2o['reordered'].asfactor()\n",
    "\n",
    "train_h2o['aisle_id'] = train_h2o['aisle_id'].asfactor()\n",
    "train_h2o['department_id'] = train_h2o['department_id'].asfactor()\n",
    "\n",
    "test_h2o['aisle_id'] = test_h2o['aisle_id'].asfactor()\n",
    "test_h2o['department_id'] = test_h2o['department_id'].asfactor()\n",
    "\n",
    "train, valid = train_h2o.split_frame(ratios=[0.8], seed=32021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f316183-d7cb-40b3-b584-c2002a4581cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'reordered'\n",
    "features = numeric_cols + categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df3a05fd-db1d-465c-993c-0cc776f31830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OXGBoostEstimator : XGBoost\n",
       "Model Key: XGBoost_grid_1_AutoML_1_20250818_235405_model_3\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>number_of_trees</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>115.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.04337805393126096\n",
       "RMSE: 0.2082739876491084\n",
       "LogLoss: 0.1566098442784407\n",
       "Mean Per-Class Error: 0.2608528071470811\n",
       "AUC: 0.9059744828287675\n",
       "AUCPR: 0.5406933348928543\n",
       "Gini: 0.8119489656575349</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2344261389528239</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>368610.0</td>\n",
       "<td>12871.0</td>\n",
       "<td>0.0337</td>\n",
       "<td> (12871.0/381481.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>12996.0</td>\n",
       "<td>13637.0</td>\n",
       "<td>0.488</td>\n",
       "<td> (12996.0/26633.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>381606.0</td>\n",
       "<td>26508.0</td>\n",
       "<td>0.0634</td>\n",
       "<td> (25867.0/408114.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2344261</td>\n",
       "<td>0.5132384</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1347738</td>\n",
       "<td>0.5819668</td>\n",
       "<td>235.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3465599</td>\n",
       "<td>0.5751454</td>\n",
       "<td>126.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3750180</td>\n",
       "<td>0.9473652</td>\n",
       "<td>116.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9088273</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0028556</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9088273</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2476601</td>\n",
       "<td>0.4796831</td>\n",
       "<td>169.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0837108</td>\n",
       "<td>0.8214621</td>\n",
       "<td>278.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0850156</td>\n",
       "<td>0.8226431</td>\n",
       "<td>277.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9088273</td>\n",
       "<td>381481.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9088273</td>\n",
       "<td>26629.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0013418</td>\n",
       "<td>381481.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0028556</td>\n",
       "<td>26633.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9088273</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9088273</td>\n",
       "<td>0.9998498</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0013418</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0028556</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate:  6.53 %, avg score:  6.53 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100021</td>\n",
       "<td>0.5272979</td>\n",
       "<td>13.6493597</td>\n",
       "<td>13.6493597</td>\n",
       "<td>0.8907398</td>\n",
       "<td>0.6287511</td>\n",
       "<td>0.8907398</td>\n",
       "<td>0.6287511</td>\n",
       "<td>0.1365224</td>\n",
       "<td>0.1365224</td>\n",
       "<td>1264.9359681</td>\n",
       "<td>1264.9359681</td>\n",
       "<td>0.1353532</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200018</td>\n",
       "<td>0.4263993</td>\n",
       "<td>10.5737116</td>\n",
       "<td>12.1117240</td>\n",
       "<td>0.6900270</td>\n",
       "<td>0.4720297</td>\n",
       "<td>0.7903957</td>\n",
       "<td>0.5504000</td>\n",
       "<td>0.1057335</td>\n",
       "<td>0.2422558</td>\n",
       "<td>957.3711575</td>\n",
       "<td>1111.1724017</td>\n",
       "<td>0.2377707</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300014</td>\n",
       "<td>0.3592944</td>\n",
       "<td>8.3320547</td>\n",
       "<td>10.8519371</td>\n",
       "<td>0.5437393</td>\n",
       "<td>0.3910023</td>\n",
       "<td>0.7081836</td>\n",
       "<td>0.4972718</td>\n",
       "<td>0.0833177</td>\n",
       "<td>0.3255735</td>\n",
       "<td>733.2054682</td>\n",
       "<td>985.1937138</td>\n",
       "<td>0.3162074</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400011</td>\n",
       "<td>0.3111608</td>\n",
       "<td>6.5672662</td>\n",
       "<td>9.7808350</td>\n",
       "<td>0.4285714</td>\n",
       "<td>0.3341029</td>\n",
       "<td>0.6382848</td>\n",
       "<td>0.4564820</td>\n",
       "<td>0.0656704</td>\n",
       "<td>0.3912439</td>\n",
       "<td>556.7266174</td>\n",
       "<td>878.0835012</td>\n",
       "<td>0.3757648</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500007</td>\n",
       "<td>0.2750092</td>\n",
       "<td>5.3206496</td>\n",
       "<td>8.8888416</td>\n",
       "<td>0.3472188</td>\n",
       "<td>0.2922579</td>\n",
       "<td>0.5800745</td>\n",
       "<td>0.4236388</td>\n",
       "<td>0.0532047</td>\n",
       "<td>0.4444486</td>\n",
       "<td>432.0649610</td>\n",
       "<td>788.8841646</td>\n",
       "<td>0.4219862</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000015</td>\n",
       "<td>0.1712266</td>\n",
       "<td>3.6435465</td>\n",
       "<td>6.2661941</td>\n",
       "<td>0.2377732</td>\n",
       "<td>0.2154344</td>\n",
       "<td>0.4089238</td>\n",
       "<td>0.3195366</td>\n",
       "<td>0.1821800</td>\n",
       "<td>0.6266286</td>\n",
       "<td>264.3546478</td>\n",
       "<td>526.6194062</td>\n",
       "<td>0.5633935</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1499998</td>\n",
       "<td>0.1213348</td>\n",
       "<td>2.1027267</td>\n",
       "<td>4.8784170</td>\n",
       "<td>0.1372213</td>\n",
       "<td>0.1439148</td>\n",
       "<td>0.3183593</td>\n",
       "<td>0.2609979</td>\n",
       "<td>0.1051327</td>\n",
       "<td>0.7317613</td>\n",
       "<td>110.2726734</td>\n",
       "<td>387.8416960</td>\n",
       "<td>0.6223771</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000005</td>\n",
       "<td>0.0912540</td>\n",
       "<td>1.3944901</td>\n",
       "<td>4.0074246</td>\n",
       "<td>0.0910026</td>\n",
       "<td>0.1052213</td>\n",
       "<td>0.2615194</td>\n",
       "<td>0.2220533</td>\n",
       "<td>0.0697255</td>\n",
       "<td>0.8014869</td>\n",
       "<td>39.4490068</td>\n",
       "<td>300.7424567</td>\n",
       "<td>0.6434790</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2999995</td>\n",
       "<td>0.0570096</td>\n",
       "<td>0.8433230</td>\n",
       "<td>2.9527326</td>\n",
       "<td>0.0550342</td>\n",
       "<td>0.0721600</td>\n",
       "<td>0.1926916</td>\n",
       "<td>0.1720893</td>\n",
       "<td>0.0843315</td>\n",
       "<td>0.8858183</td>\n",
       "<td>-15.6677050</td>\n",
       "<td>195.2732642</td>\n",
       "<td>0.6267176</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000010</td>\n",
       "<td>0.0382527</td>\n",
       "<td>0.4971203</td>\n",
       "<td>2.3388220</td>\n",
       "<td>0.0324414</td>\n",
       "<td>0.0468264</td>\n",
       "<td>0.1526285</td>\n",
       "<td>0.1407732</td>\n",
       "<td>0.0497128</td>\n",
       "<td>0.9355311</td>\n",
       "<td>-50.2879685</td>\n",
       "<td>133.8822039</td>\n",
       "<td>0.5729180</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0264959</td>\n",
       "<td>0.2842366</td>\n",
       "<td>1.9279090</td>\n",
       "<td>0.0185489</td>\n",
       "<td>0.0319762</td>\n",
       "<td>0.1258129</td>\n",
       "<td>0.1190140</td>\n",
       "<td>0.0284234</td>\n",
       "<td>0.9639545</td>\n",
       "<td>-71.5763369</td>\n",
       "<td>92.7908985</td>\n",
       "<td>0.4963454</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5999990</td>\n",
       "<td>0.0184749</td>\n",
       "<td>0.1689650</td>\n",
       "<td>1.6347540</td>\n",
       "<td>0.0110264</td>\n",
       "<td>0.0222756</td>\n",
       "<td>0.1066820</td>\n",
       "<td>0.1028911</td>\n",
       "<td>0.0168963</td>\n",
       "<td>0.9808508</td>\n",
       "<td>-83.1035028</td>\n",
       "<td>63.4754044</td>\n",
       "<td>0.4074409</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000005</td>\n",
       "<td>0.0126565</td>\n",
       "<td>0.1032538</td>\n",
       "<td>1.4159652</td>\n",
       "<td>0.0067382</td>\n",
       "<td>0.0154151</td>\n",
       "<td>0.0924041</td>\n",
       "<td>0.0903943</td>\n",
       "<td>0.0103255</td>\n",
       "<td>0.9911764</td>\n",
       "<td>-89.6746158</td>\n",
       "<td>41.5965237</td>\n",
       "<td>0.3115042</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7999995</td>\n",
       "<td>0.0082304</td>\n",
       "<td>0.0540688</td>\n",
       "<td>1.2457297</td>\n",
       "<td>0.0035285</td>\n",
       "<td>0.0103432</td>\n",
       "<td>0.0812947</td>\n",
       "<td>0.0803880</td>\n",
       "<td>0.0054068</td>\n",
       "<td>0.9965832</td>\n",
       "<td>-94.5931209</td>\n",
       "<td>24.5729746</td>\n",
       "<td>0.2103081</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999985</td>\n",
       "<td>0.0047508</td>\n",
       "<td>0.0296627</td>\n",
       "<td>1.1106123</td>\n",
       "<td>0.0019358</td>\n",
       "<td>0.0064306</td>\n",
       "<td>0.0724771</td>\n",
       "<td>0.0721706</td>\n",
       "<td>0.0029662</td>\n",
       "<td>0.9995494</td>\n",
       "<td>-97.0337260</td>\n",
       "<td>11.0612293</td>\n",
       "<td>0.1065010</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0004211</td>\n",
       "<td>0.0045056</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0002940</td>\n",
       "<td>0.0031287</td>\n",
       "<td>0.0652587</td>\n",
       "<td>0.0652663</td>\n",
       "<td>0.0004506</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.5494378</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.05004561865809638\n",
       "RMSE: 0.22370878091415272\n",
       "LogLoss: 0.18335358634857185\n",
       "Mean Per-Class Error: 0.3084172947113857\n",
       "AUC: 0.8446143124073078\n",
       "AUCPR: 0.35789994556673915\n",
       "Gini: 0.6892286248146156</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.20369456627446672</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>89993.0</td>\n",
       "<td>5107.0</td>\n",
       "<td>0.0537</td>\n",
       "<td> (5107.0/95100.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>3724.0</td>\n",
       "<td>2889.0</td>\n",
       "<td>0.5631</td>\n",
       "<td> (3724.0/6613.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>93717.0</td>\n",
       "<td>7996.0</td>\n",
       "<td>0.0868</td>\n",
       "<td> (8831.0/101713.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2036946</td>\n",
       "<td>0.3955096</td>\n",
       "<td>185.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1016175</td>\n",
       "<td>0.4871172</td>\n",
       "<td>256.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3282532</td>\n",
       "<td>0.4218082</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4524168</td>\n",
       "<td>0.9380512</td>\n",
       "<td>76.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8508968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0012640</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.8508968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2110715</td>\n",
       "<td>0.3511625</td>\n",
       "<td>181.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0660766</td>\n",
       "<td>0.7634961</td>\n",
       "<td>291.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0669451</td>\n",
       "<td>0.7649903</td>\n",
       "<td>290.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.8508968</td>\n",
       "<td>95100.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.8508968</td>\n",
       "<td>6612.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0012640</td>\n",
       "<td>95100.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0012640</td>\n",
       "<td>6613.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.8508968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.8508968</td>\n",
       "<td>0.9998488</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0012640</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0012640</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate:  6.50 %, avg score:  6.41 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100086</td>\n",
       "<td>0.4977545</td>\n",
       "<td>9.7451803</td>\n",
       "<td>9.7451803</td>\n",
       "<td>0.6335953</td>\n",
       "<td>0.6002116</td>\n",
       "<td>0.6335953</td>\n",
       "<td>0.6002116</td>\n",
       "<td>0.0975352</td>\n",
       "<td>0.0975352</td>\n",
       "<td>874.5180283</td>\n",
       "<td>874.5180283</td>\n",
       "<td>0.0936130</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200073</td>\n",
       "<td>0.4022680</td>\n",
       "<td>7.5769551</td>\n",
       "<td>8.6616004</td>\n",
       "<td>0.4926254</td>\n",
       "<td>0.4456633</td>\n",
       "<td>0.5631450</td>\n",
       "<td>0.5229754</td>\n",
       "<td>0.0757599</td>\n",
       "<td>0.1732950</td>\n",
       "<td>657.6955108</td>\n",
       "<td>766.1600429</td>\n",
       "<td>0.1639470</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300060</td>\n",
       "<td>0.3438383</td>\n",
       "<td>6.4729277</td>\n",
       "<td>7.9322819</td>\n",
       "<td>0.4208456</td>\n",
       "<td>0.3710530</td>\n",
       "<td>0.5157274</td>\n",
       "<td>0.4723512</td>\n",
       "<td>0.0647210</td>\n",
       "<td>0.2380160</td>\n",
       "<td>547.2927717</td>\n",
       "<td>693.2281901</td>\n",
       "<td>0.2224745</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400047</td>\n",
       "<td>0.3006980</td>\n",
       "<td>5.0664271</td>\n",
       "<td>7.2159943</td>\n",
       "<td>0.3294002</td>\n",
       "<td>0.3222146</td>\n",
       "<td>0.4691570</td>\n",
       "<td>0.4348263</td>\n",
       "<td>0.0506578</td>\n",
       "<td>0.2886738</td>\n",
       "<td>406.6427068</td>\n",
       "<td>621.5994271</td>\n",
       "<td>0.2659609</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500034</td>\n",
       "<td>0.2664456</td>\n",
       "<td>4.7639538</td>\n",
       "<td>6.7256826</td>\n",
       "<td>0.3097345</td>\n",
       "<td>0.2837124</td>\n",
       "<td>0.4372788</td>\n",
       "<td>0.4046094</td>\n",
       "<td>0.0476334</td>\n",
       "<td>0.3363073</td>\n",
       "<td>376.3953810</td>\n",
       "<td>572.5682602</td>\n",
       "<td>0.3062126</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000069</td>\n",
       "<td>0.1694614</td>\n",
       "<td>3.2116344</td>\n",
       "<td>4.9686585</td>\n",
       "<td>0.2088085</td>\n",
       "<td>0.2121755</td>\n",
       "<td>0.3230436</td>\n",
       "<td>0.3083924</td>\n",
       "<td>0.1605928</td>\n",
       "<td>0.4969000</td>\n",
       "<td>221.1634408</td>\n",
       "<td>396.8658505</td>\n",
       "<td>0.4244921</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500005</td>\n",
       "<td>0.1203659</td>\n",
       "<td>2.1868817</td>\n",
       "<td>4.0415211</td>\n",
       "<td>0.1421829</td>\n",
       "<td>0.1427555</td>\n",
       "<td>0.2627646</td>\n",
       "<td>0.2531874</td>\n",
       "<td>0.1093301</td>\n",
       "<td>0.6062302</td>\n",
       "<td>118.6881654</td>\n",
       "<td>304.1521107</td>\n",
       "<td>0.4879547</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000039</td>\n",
       "<td>0.0912312</td>\n",
       "<td>1.5392862</td>\n",
       "<td>3.4159316</td>\n",
       "<td>0.1000786</td>\n",
       "<td>0.1048753</td>\n",
       "<td>0.2220911</td>\n",
       "<td>0.2161075</td>\n",
       "<td>0.0769696</td>\n",
       "<td>0.6831998</td>\n",
       "<td>53.9286171</td>\n",
       "<td>241.5931622</td>\n",
       "<td>0.5167960</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000010</td>\n",
       "<td>0.0571934</td>\n",
       "<td>1.0751867</td>\n",
       "<td>2.6357089</td>\n",
       "<td>0.0699046</td>\n",
       "<td>0.0722682</td>\n",
       "<td>0.1713640</td>\n",
       "<td>0.1681626</td>\n",
       "<td>0.1075155</td>\n",
       "<td>0.7907153</td>\n",
       "<td>7.5186710</td>\n",
       "<td>163.5708888</td>\n",
       "<td>0.5248372</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3999980</td>\n",
       "<td>0.0383338</td>\n",
       "<td>0.7198156</td>\n",
       "<td>2.1567473</td>\n",
       "<td>0.0467997</td>\n",
       "<td>0.0468491</td>\n",
       "<td>0.1402237</td>\n",
       "<td>0.1378350</td>\n",
       "<td>0.0719794</td>\n",
       "<td>0.8626947</td>\n",
       "<td>-28.0184425</td>\n",
       "<td>115.6747333</td>\n",
       "<td>0.4948713</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000049</td>\n",
       "<td>0.0265420</td>\n",
       "<td>0.4702534</td>\n",
       "<td>1.8194287</td>\n",
       "<td>0.0305741</td>\n",
       "<td>0.0320689</td>\n",
       "<td>0.1182925</td>\n",
       "<td>0.1166805</td>\n",
       "<td>0.0470286</td>\n",
       "<td>0.9097233</td>\n",
       "<td>-52.9746563</td>\n",
       "<td>81.9428657</td>\n",
       "<td>0.4382091</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000020</td>\n",
       "<td>0.0184349</td>\n",
       "<td>0.3599078</td>\n",
       "<td>1.5761832</td>\n",
       "<td>0.0233999</td>\n",
       "<td>0.0222656</td>\n",
       "<td>0.1024776</td>\n",
       "<td>0.1009452</td>\n",
       "<td>0.0359897</td>\n",
       "<td>0.9457130</td>\n",
       "<td>-64.0092212</td>\n",
       "<td>57.6183150</td>\n",
       "<td>0.3697508</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6999990</td>\n",
       "<td>0.0126806</td>\n",
       "<td>0.2464915</td>\n",
       "<td>1.3862325</td>\n",
       "<td>0.0160260</td>\n",
       "<td>0.0154306</td>\n",
       "<td>0.0901277</td>\n",
       "<td>0.0887292</td>\n",
       "<td>0.0246484</td>\n",
       "<td>0.9703614</td>\n",
       "<td>-75.3508532</td>\n",
       "<td>38.6232532</td>\n",
       "<td>0.2891627</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7999961</td>\n",
       "<td>0.0082275</td>\n",
       "<td>0.1512218</td>\n",
       "<td>1.2318600</td>\n",
       "<td>0.0098319</td>\n",
       "<td>0.0103422</td>\n",
       "<td>0.0800909</td>\n",
       "<td>0.0789311</td>\n",
       "<td>0.0151217</td>\n",
       "<td>0.9854831</td>\n",
       "<td>-84.8778240</td>\n",
       "<td>23.1859980</td>\n",
       "<td>0.1983853</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999931</td>\n",
       "<td>0.0047358</td>\n",
       "<td>0.1028308</td>\n",
       "<td>1.1064150</td>\n",
       "<td>0.0066857</td>\n",
       "<td>0.0064361</td>\n",
       "<td>0.0719350</td>\n",
       "<td>0.0708762</td>\n",
       "<td>0.0102828</td>\n",
       "<td>0.9957659</td>\n",
       "<td>-89.7169204</td>\n",
       "<td>10.6415033</td>\n",
       "<td>0.1024326</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0006109</td>\n",
       "<td>0.0423379</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0027527</td>\n",
       "<td>0.0031277</td>\n",
       "<td>0.0650163</td>\n",
       "<td>0.0641009</td>\n",
       "<td>0.0042341</td>\n",
       "<td>1.0</td>\n",
       "<td>-95.7662070</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>number_of_trees</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-08-19 00:05:17</td>\n",
       "<td> 7 min 29.831 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0652587</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9347413</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0650163</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9349837</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:05:19</td>\n",
       "<td> 7 min 31.419 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.2510640</td>\n",
       "<td>0.2563795</td>\n",
       "<td>0.7795201</td>\n",
       "<td>0.2572316</td>\n",
       "<td>7.6486749</td>\n",
       "<td>0.1085015</td>\n",
       "<td>0.2515575</td>\n",
       "<td>0.2570448</td>\n",
       "<td>0.7750008</td>\n",
       "<td>0.2347029</td>\n",
       "<td>6.3003724</td>\n",
       "<td>0.1171040</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:05:21</td>\n",
       "<td> 7 min 34.255 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.2306797</td>\n",
       "<td>0.2029434</td>\n",
       "<td>0.8158275</td>\n",
       "<td>0.3102914</td>\n",
       "<td>9.0132323</td>\n",
       "<td>0.0996780</td>\n",
       "<td>0.2326565</td>\n",
       "<td>0.2061320</td>\n",
       "<td>0.8040217</td>\n",
       "<td>0.2722811</td>\n",
       "<td>7.7054914</td>\n",
       "<td>0.1073904</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:05:25</td>\n",
       "<td> 7 min 37.612 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.2269240</td>\n",
       "<td>0.1909913</td>\n",
       "<td>0.8321137</td>\n",
       "<td>0.3436830</td>\n",
       "<td>9.9141801</td>\n",
       "<td>0.0947186</td>\n",
       "<td>0.2301916</td>\n",
       "<td>0.1967611</td>\n",
       "<td>0.8144463</td>\n",
       "<td>0.2906628</td>\n",
       "<td>8.4760405</td>\n",
       "<td>0.1036347</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:05:28</td>\n",
       "<td> 7 min 40.847 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.2245113</td>\n",
       "<td>0.1854449</td>\n",
       "<td>0.8438584</td>\n",
       "<td>0.3711360</td>\n",
       "<td>10.7250332</td>\n",
       "<td>0.0891295</td>\n",
       "<td>0.2287394</td>\n",
       "<td>0.1932464</td>\n",
       "<td>0.8213715</td>\n",
       "<td>0.3078056</td>\n",
       "<td>9.1257192</td>\n",
       "<td>0.0954155</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:05:31</td>\n",
       "<td> 7 min 44.137 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.2226561</td>\n",
       "<td>0.1817028</td>\n",
       "<td>0.8518789</td>\n",
       "<td>0.3918111</td>\n",
       "<td>11.2280624</td>\n",
       "<td>0.0834595</td>\n",
       "<td>0.2277992</td>\n",
       "<td>0.1911337</td>\n",
       "<td>0.8263922</td>\n",
       "<td>0.3172777</td>\n",
       "<td>9.3523513</td>\n",
       "<td>0.0945995</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:05:34</td>\n",
       "<td> 7 min 46.921 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.2215166</td>\n",
       "<td>0.1795136</td>\n",
       "<td>0.8568037</td>\n",
       "<td>0.4034662</td>\n",
       "<td>11.3857282</td>\n",
       "<td>0.0839912</td>\n",
       "<td>0.2272511</td>\n",
       "<td>0.1900325</td>\n",
       "<td>0.8289673</td>\n",
       "<td>0.3221677</td>\n",
       "<td>9.4278953</td>\n",
       "<td>0.0982667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:05:37</td>\n",
       "<td> 7 min 49.727 sec</td>\n",
       "<td>35.0</td>\n",
       "<td>0.2203680</td>\n",
       "<td>0.1774516</td>\n",
       "<td>0.8614107</td>\n",
       "<td>0.4159644</td>\n",
       "<td>11.6184731</td>\n",
       "<td>0.0803869</td>\n",
       "<td>0.2267705</td>\n",
       "<td>0.1891608</td>\n",
       "<td>0.8309821</td>\n",
       "<td>0.3269241</td>\n",
       "<td>9.4278953</td>\n",
       "<td>0.1024943</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:05:40</td>\n",
       "<td> 7 min 52.840 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.2195199</td>\n",
       "<td>0.1758876</td>\n",
       "<td>0.8649049</td>\n",
       "<td>0.4244504</td>\n",
       "<td>11.8437101</td>\n",
       "<td>0.0815458</td>\n",
       "<td>0.2264187</td>\n",
       "<td>0.1885433</td>\n",
       "<td>0.8322078</td>\n",
       "<td>0.3310781</td>\n",
       "<td>9.5940922</td>\n",
       "<td>0.1018159</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:05:44</td>\n",
       "<td> 7 min 56.530 sec</td>\n",
       "<td>45.0</td>\n",
       "<td>0.2182544</td>\n",
       "<td>0.1735399</td>\n",
       "<td>0.8704687</td>\n",
       "<td>0.4384324</td>\n",
       "<td>12.1064865</td>\n",
       "<td>0.0788603</td>\n",
       "<td>0.2259275</td>\n",
       "<td>0.1876199</td>\n",
       "<td>0.8344410</td>\n",
       "<td>0.3363075</td>\n",
       "<td>9.6243098</td>\n",
       "<td>0.0998004</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:06:00</td>\n",
       "<td> 8 min 12.851 sec</td>\n",
       "<td>70.0</td>\n",
       "<td>0.2135050</td>\n",
       "<td>0.1653597</td>\n",
       "<td>0.8882296</td>\n",
       "<td>0.4884175</td>\n",
       "<td>12.9023238</td>\n",
       "<td>0.0708160</td>\n",
       "<td>0.2246775</td>\n",
       "<td>0.1851188</td>\n",
       "<td>0.8407313</td>\n",
       "<td>0.3478388</td>\n",
       "<td>9.6243098</td>\n",
       "<td>0.0860952</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:06:03</td>\n",
       "<td> 8 min 16.146 sec</td>\n",
       "<td>75.0</td>\n",
       "<td>0.2129395</td>\n",
       "<td>0.1643846</td>\n",
       "<td>0.8902513</td>\n",
       "<td>0.4942141</td>\n",
       "<td>12.9886646</td>\n",
       "<td>0.0695492</td>\n",
       "<td>0.2245604</td>\n",
       "<td>0.1849060</td>\n",
       "<td>0.8412182</td>\n",
       "<td>0.3492542</td>\n",
       "<td>9.6394186</td>\n",
       "<td>0.0884843</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:06:07</td>\n",
       "<td> 8 min 19.735 sec</td>\n",
       "<td>80.0</td>\n",
       "<td>0.2122282</td>\n",
       "<td>0.1632290</td>\n",
       "<td>0.8926419</td>\n",
       "<td>0.5016928</td>\n",
       "<td>13.1200528</td>\n",
       "<td>0.0682162</td>\n",
       "<td>0.2243785</td>\n",
       "<td>0.1845914</td>\n",
       "<td>0.8418999</td>\n",
       "<td>0.3511793</td>\n",
       "<td>9.7451803</td>\n",
       "<td>0.0900475</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:06:11</td>\n",
       "<td> 8 min 23.480 sec</td>\n",
       "<td>85.0</td>\n",
       "<td>0.2116020</td>\n",
       "<td>0.1621648</td>\n",
       "<td>0.8947804</td>\n",
       "<td>0.5076238</td>\n",
       "<td>13.1688542</td>\n",
       "<td>0.0667289</td>\n",
       "<td>0.2241895</td>\n",
       "<td>0.1842422</td>\n",
       "<td>0.8427118</td>\n",
       "<td>0.3534511</td>\n",
       "<td>9.8056155</td>\n",
       "<td>0.0866261</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:06:14</td>\n",
       "<td> 8 min 27.238 sec</td>\n",
       "<td>90.0</td>\n",
       "<td>0.2107117</td>\n",
       "<td>0.1606418</td>\n",
       "<td>0.8978755</td>\n",
       "<td>0.5159528</td>\n",
       "<td>13.3190121</td>\n",
       "<td>0.0677164</td>\n",
       "<td>0.2239340</td>\n",
       "<td>0.1838028</td>\n",
       "<td>0.8436171</td>\n",
       "<td>0.3558509</td>\n",
       "<td>9.7905067</td>\n",
       "<td>0.0890742</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:06:18</td>\n",
       "<td> 8 min 31.013 sec</td>\n",
       "<td>95.0</td>\n",
       "<td>0.2101093</td>\n",
       "<td>0.1596963</td>\n",
       "<td>0.8996872</td>\n",
       "<td>0.5224614</td>\n",
       "<td>13.4203688</td>\n",
       "<td>0.0655111</td>\n",
       "<td>0.2238838</td>\n",
       "<td>0.1836681</td>\n",
       "<td>0.8440379</td>\n",
       "<td>0.3562419</td>\n",
       "<td>9.8509419</td>\n",
       "<td>0.0920335</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:06:22</td>\n",
       "<td> 8 min 35.154 sec</td>\n",
       "<td>100.0</td>\n",
       "<td>0.2094377</td>\n",
       "<td>0.1585640</td>\n",
       "<td>0.9020117</td>\n",
       "<td>0.5292386</td>\n",
       "<td>13.4992017</td>\n",
       "<td>0.0645040</td>\n",
       "<td>0.2238379</td>\n",
       "<td>0.1836060</td>\n",
       "<td>0.8440899</td>\n",
       "<td>0.3568712</td>\n",
       "<td>9.8509419</td>\n",
       "<td>0.0887104</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:06:26</td>\n",
       "<td> 8 min 38.828 sec</td>\n",
       "<td>105.0</td>\n",
       "<td>0.2091167</td>\n",
       "<td>0.1580274</td>\n",
       "<td>0.9030708</td>\n",
       "<td>0.5323205</td>\n",
       "<td>13.5592649</td>\n",
       "<td>0.0665476</td>\n",
       "<td>0.2238025</td>\n",
       "<td>0.1835292</td>\n",
       "<td>0.8442361</td>\n",
       "<td>0.3568958</td>\n",
       "<td>9.8207243</td>\n",
       "<td>0.0886121</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:06:30</td>\n",
       "<td> 8 min 42.828 sec</td>\n",
       "<td>110.0</td>\n",
       "<td>0.2086058</td>\n",
       "<td>0.1571738</td>\n",
       "<td>0.9047739</td>\n",
       "<td>0.5373330</td>\n",
       "<td>13.6568676</td>\n",
       "<td>0.0647368</td>\n",
       "<td>0.2237163</td>\n",
       "<td>0.1833869</td>\n",
       "<td>0.8445198</td>\n",
       "<td>0.3578424</td>\n",
       "<td>9.8358331</td>\n",
       "<td>0.0871668</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-08-19 00:06:34</td>\n",
       "<td> 8 min 46.438 sec</td>\n",
       "<td>115.0</td>\n",
       "<td>0.2082740</td>\n",
       "<td>0.1566098</td>\n",
       "<td>0.9059745</td>\n",
       "<td>0.5406933</td>\n",
       "<td>13.6493597</td>\n",
       "<td>0.0633818</td>\n",
       "<td>0.2237088</td>\n",
       "<td>0.1833536</td>\n",
       "<td>0.8446143</td>\n",
       "<td>0.3578999</td>\n",
       "<td>9.7451803</td>\n",
       "<td>0.0868227</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[24 rows x 16 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>times_bought_by_user</td>\n",
       "<td>25957.6367188</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2315935</td></tr>\n",
       "<tr><td>num_orders</td>\n",
       "<td>16035.4169922</td>\n",
       "<td>0.6177533</td>\n",
       "<td>0.1430677</td></tr>\n",
       "<tr><td>user_reorder_prop</td>\n",
       "<td>13584.8310547</td>\n",
       "<td>0.5233462</td>\n",
       "<td>0.1212036</td></tr>\n",
       "<tr><td>num_items</td>\n",
       "<td>12737.8144531</td>\n",
       "<td>0.4907155</td>\n",
       "<td>0.1136465</td></tr>\n",
       "<tr><td>avg_days_since_prior_order</td>\n",
       "<td>12266.5117188</td>\n",
       "<td>0.4725589</td>\n",
       "<td>0.1094416</td></tr>\n",
       "<tr><td>last_order_number</td>\n",
       "<td>10680.7441406</td>\n",
       "<td>0.4114683</td>\n",
       "<td>0.0952934</td></tr>\n",
       "<tr><td>product_reorder_prop</td>\n",
       "<td>7650.6098633</td>\n",
       "<td>0.2947345</td>\n",
       "<td>0.0682586</td></tr>\n",
       "<tr><td>product_total_orders</td>\n",
       "<td>4036.3142090</td>\n",
       "<td>0.1554962</td>\n",
       "<td>0.0360119</td></tr>\n",
       "<tr><td>avg_add_to_cart_order</td>\n",
       "<td>3637.2243652</td>\n",
       "<td>0.1401216</td>\n",
       "<td>0.0324512</td></tr>\n",
       "<tr><td>avg_user_product_position</td>\n",
       "<td>3061.6958008</td>\n",
       "<td>0.1179497</td>\n",
       "<td>0.0273164</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>aisle_id.57</td>\n",
       "<td>1.6125641</td>\n",
       "<td>0.0000621</td>\n",
       "<td>0.0000144</td></tr>\n",
       "<tr><td>aisle_id.129</td>\n",
       "<td>1.3888421</td>\n",
       "<td>0.0000535</td>\n",
       "<td>0.0000124</td></tr>\n",
       "<tr><td>aisle_id.30</td>\n",
       "<td>1.1755202</td>\n",
       "<td>0.0000453</td>\n",
       "<td>0.0000105</td></tr>\n",
       "<tr><td>aisle_id.85</td>\n",
       "<td>1.1435547</td>\n",
       "<td>0.0000441</td>\n",
       "<td>0.0000102</td></tr>\n",
       "<tr><td>aisle_id.28</td>\n",
       "<td>0.9485786</td>\n",
       "<td>0.0000365</td>\n",
       "<td>0.0000085</td></tr>\n",
       "<tr><td>aisle_id.6</td>\n",
       "<td>0.9269781</td>\n",
       "<td>0.0000357</td>\n",
       "<td>0.0000083</td></tr>\n",
       "<tr><td>aisle_id.49</td>\n",
       "<td>0.5939789</td>\n",
       "<td>0.0000229</td>\n",
       "<td>0.0000053</td></tr>\n",
       "<tr><td>aisle_id.67</td>\n",
       "<td>0.2189331</td>\n",
       "<td>0.0000084</td>\n",
       "<td>0.0000020</td></tr>\n",
       "<tr><td>aisle_id.9</td>\n",
       "<td>0.1435924</td>\n",
       "<td>0.0000055</td>\n",
       "<td>0.0000013</td></tr>\n",
       "<tr><td>aisle_id.17</td>\n",
       "<td>0.1195118</td>\n",
       "<td>0.0000046</td>\n",
       "<td>0.0000011</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[94 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OXGBoostEstimator : XGBoost\n",
       "Model Key: XGBoost_grid_1_AutoML_1_20250818_235405_model_3\n",
       "\n",
       "\n",
       "Model Summary: \n",
       "    number_of_trees\n",
       "--  -----------------\n",
       "    115\n",
       "\n",
       "ModelMetricsBinomial: xgboost\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.04337805393126096\n",
       "RMSE: 0.2082739876491084\n",
       "LogLoss: 0.1566098442784407\n",
       "Mean Per-Class Error: 0.2608528071470811\n",
       "AUC: 0.9059744828287675\n",
       "AUCPR: 0.5406933348928543\n",
       "Gini: 0.8119489656575349\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2344261389528239\n",
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      368610  12871  0.0337   (12871.0/381481.0)\n",
       "1      12996   13637  0.488    (12996.0/26633.0)\n",
       "Total  381606  26508  0.0634   (25867.0/408114.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.234426     0.513238  175\n",
       "max f2                       0.134774     0.581967  235\n",
       "max f0point5                 0.34656      0.575145  126\n",
       "max accuracy                 0.375018     0.947365  116\n",
       "max precision                0.908827     1         0\n",
       "max recall                   0.00285563   1         396\n",
       "max specificity              0.908827     1         0\n",
       "max absolute_mcc             0.24766      0.479683  169\n",
       "max min_per_class_accuracy   0.0837108    0.821462  278\n",
       "max mean_per_class_accuracy  0.0850156    0.822643  277\n",
       "max tns                      0.908827     381481    0\n",
       "max fns                      0.908827     26629     0\n",
       "max fps                      0.00134184   381481    399\n",
       "max tps                      0.00285563   26633     396\n",
       "max tnr                      0.908827     1         0\n",
       "max fnr                      0.908827     0.99985   0\n",
       "max fpr                      0.00134184   1         399\n",
       "max tpr                      0.00285563   1         396\n",
       "\n",
       "Gains/Lift Table: Avg response rate:  6.53 %, avg score:  6.53 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100021                   0.527298           13.6494     13.6494            0.89074          0.628751    0.89074                     0.628751            0.136522        0.136522                   1264.94   1264.94            0.135353\n",
       "2        0.0200018                   0.426399           10.5737     12.1117            0.690027         0.47203     0.790396                    0.5504              0.105733        0.242256                   957.371   1111.17            0.237771\n",
       "3        0.0300014                   0.359294           8.33205     10.8519            0.543739         0.391002    0.708184                    0.497272            0.0833177       0.325574                   733.205   985.194            0.316207\n",
       "4        0.0400011                   0.311161           6.56727     9.78084            0.428571         0.334103    0.638285                    0.456482            0.0656704       0.391244                   556.727   878.084            0.375765\n",
       "5        0.0500007                   0.275009           5.32065     8.88884            0.347219         0.292258    0.580074                    0.423639            0.0532047       0.444449                   432.065   788.884            0.421986\n",
       "6        0.100001                    0.171227           3.64355     6.26619            0.237773         0.215434    0.408924                    0.319537            0.18218         0.626629                   264.355   526.619            0.563393\n",
       "7        0.15                        0.121335           2.10273     4.87842            0.137221         0.143915    0.318359                    0.260998            0.105133        0.731761                   110.273   387.842            0.622377\n",
       "8        0.2                         0.091254           1.39449     4.00742            0.0910026        0.105221    0.261519                    0.222053            0.0697255       0.801487                   39.449    300.742            0.643479\n",
       "9        0.3                         0.0570096          0.843323    2.95273            0.0550342        0.07216     0.192692                    0.172089            0.0843315       0.885818                   -15.6677  195.273            0.626718\n",
       "10       0.400001                    0.0382527          0.49712     2.33882            0.0324414        0.0468264   0.152629                    0.140773            0.0497128       0.935531                   -50.288   133.882            0.572918\n",
       "11       0.5                         0.0264959          0.284237    1.92791            0.0185489        0.0319762   0.125813                    0.119014            0.0284234       0.963954                   -71.5763  92.7909            0.496345\n",
       "12       0.599999                    0.0184749          0.168965    1.63475            0.0110264        0.0222756   0.106682                    0.102891            0.0168963       0.980851                   -83.1035  63.4754            0.407441\n",
       "13       0.7                         0.0126565          0.103254    1.41597            0.00673821       0.0154151   0.0924041                   0.0903943           0.0103255       0.991176                   -89.6746  41.5965            0.311504\n",
       "14       0.8                         0.0082304          0.0540688   1.24573            0.00352846       0.0103432   0.0812947                   0.080388            0.00540683      0.996583                   -94.5931  24.573             0.210308\n",
       "15       0.899999                    0.0047508          0.0296627   1.11061            0.00193575       0.00643065  0.0724771                   0.0721706           0.00296624      0.999549                   -97.0337  11.0612            0.106501\n",
       "16       1                           0.000421136        0.00450562  1                  0.000294031      0.00312866  0.0652587                   0.0652663           0.000450569     1                          -99.5494  0                  0\n",
       "\n",
       "ModelMetricsBinomial: xgboost\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.05004561865809638\n",
       "RMSE: 0.22370878091415272\n",
       "LogLoss: 0.18335358634857185\n",
       "Mean Per-Class Error: 0.3084172947113857\n",
       "AUC: 0.8446143124073078\n",
       "AUCPR: 0.35789994556673915\n",
       "Gini: 0.6892286248146156\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.20369456627446672\n",
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  -----------------\n",
       "0      89993  5107  0.0537   (5107.0/95100.0)\n",
       "1      3724   2889  0.5631   (3724.0/6613.0)\n",
       "Total  93717  7996  0.0868   (8831.0/101713.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.203695     0.39551   185\n",
       "max f2                       0.101618     0.487117  256\n",
       "max f0point5                 0.328253     0.421808  124\n",
       "max accuracy                 0.452417     0.938051  76\n",
       "max precision                0.850897     1         0\n",
       "max recall                   0.00126396   1         399\n",
       "max specificity              0.850897     1         0\n",
       "max absolute_mcc             0.211071     0.351163  181\n",
       "max min_per_class_accuracy   0.0660766    0.763496  291\n",
       "max mean_per_class_accuracy  0.0669451    0.76499   290\n",
       "max tns                      0.850897     95100     0\n",
       "max fns                      0.850897     6612      0\n",
       "max fps                      0.00126396   95100     399\n",
       "max tps                      0.00126396   6613      399\n",
       "max tnr                      0.850897     1         0\n",
       "max fnr                      0.850897     0.999849  0\n",
       "max fpr                      0.00126396   1         399\n",
       "max tpr                      0.00126396   1         399\n",
       "\n",
       "Gains/Lift Table: Avg response rate:  6.50 %, avg score:  6.41 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100086                   0.497755           9.74518    9.74518            0.633595         0.600212    0.633595                    0.600212            0.0975352       0.0975352                  874.518   874.518            0.093613\n",
       "2        0.0200073                   0.402268           7.57696    8.6616             0.492625         0.445663    0.563145                    0.522975            0.0757599       0.173295                   657.696   766.16             0.163947\n",
       "3        0.030006                    0.343838           6.47293    7.93228            0.420846         0.371053    0.515727                    0.472351            0.064721        0.238016                   547.293   693.228            0.222474\n",
       "4        0.0400047                   0.300698           5.06643    7.21599            0.3294           0.322215    0.469157                    0.434826            0.0506578       0.288674                   406.643   621.599            0.265961\n",
       "5        0.0500034                   0.266446           4.76395    6.72568            0.309735         0.283712    0.437279                    0.404609            0.0476334       0.336307                   376.395   572.568            0.306213\n",
       "6        0.100007                    0.169461           3.21163    4.96866            0.208808         0.212175    0.323044                    0.308392            0.160593        0.4969                     221.163   396.866            0.424492\n",
       "7        0.15                        0.120366           2.18688    4.04152            0.142183         0.142756    0.262765                    0.253187            0.10933         0.60623                    118.688   304.152            0.487955\n",
       "8        0.200004                    0.0912312          1.53929    3.41593            0.100079         0.104875    0.222091                    0.216108            0.0769696       0.6832                     53.9286   241.593            0.516796\n",
       "9        0.300001                    0.0571934          1.07519    2.63571            0.0699046        0.0722682   0.171364                    0.168163            0.107515        0.790715                   7.51867   163.571            0.524837\n",
       "10       0.399998                    0.0383338          0.719816   2.15675            0.0467997        0.0468491   0.140224                    0.137835            0.0719794       0.862695                   -28.0184  115.675            0.494871\n",
       "11       0.500005                    0.026542           0.470253   1.81943            0.0305741        0.0320689   0.118292                    0.116681            0.0470286       0.909723                   -52.9747  81.9429            0.438209\n",
       "12       0.600002                    0.0184349          0.359908   1.57618            0.0233999        0.0222656   0.102478                    0.100945            0.0359897       0.945713                   -64.0092  57.6183            0.369751\n",
       "13       0.699999                    0.0126806          0.246491   1.38623            0.016026         0.0154306   0.0901277                   0.0887292           0.0246484       0.970361                   -75.3509  38.6233            0.289163\n",
       "14       0.799996                    0.00822754         0.151222   1.23186            0.00983187       0.0103422   0.0800909                   0.0789311           0.0151217       0.985483                   -84.8778  23.186             0.198385\n",
       "15       0.899993                    0.00473585         0.102831   1.10642            0.00668567       0.00643609  0.071935                    0.0708762           0.0102828       0.995766                   -89.7169  10.6415            0.102433\n",
       "16       1                           0.000610906        0.0423379  1                  0.00275265       0.00312774  0.0650163                   0.0641009           0.00423408      1                          -95.7662  0                  0\n",
       "\n",
       "Scoring History: \n",
       "     timestamp            duration          number_of_trees    training_rmse        training_logloss     training_auc        training_pr_auc      training_lift       training_classification_error    validation_rmse      validation_logloss    validation_auc      validation_pr_auc    validation_lift    validation_classification_error\n",
       "---  -------------------  ----------------  -----------------  -------------------  -------------------  ------------------  -------------------  ------------------  -------------------------------  -------------------  --------------------  ------------------  -------------------  -----------------  ---------------------------------\n",
       "     2025-08-19 00:05:17  7 min 29.831 sec  0.0                0.5                  0.693147180559752    0.5                 0.0652587267283161   1.0                 0.9347412732716839               0.5                  0.693147180560031     0.5                 0.06501627127309194  1.0                0.934983728726908\n",
       "     2025-08-19 00:05:19  7 min 31.419 sec  5.0                0.2510640033336335   0.25637946283726853  0.7795200661051312  0.257231594826234    7.648674931160105   0.10850154613661869              0.25155745955787867  0.2570447992421425    0.7750008292305106  0.23470290658905404  6.300372368885837  0.11710400833718404\n",
       "     2025-08-19 00:05:21  7 min 34.255 sec  10.0               0.23067966284377117  0.20294343809200885  0.8158274551358614  0.31029137300970316  9.013232286359276   0.0996780311383584               0.2326565370575483   0.20613201921195773   0.8040216725714557  0.27228113859276426  7.705491386407139  0.107390402406772\n",
       "     2025-08-19 00:05:25  7 min 37.612 sec  15.0               0.22692396902690806  0.1909913323583545   0.8321137246401109  0.34368302651781796  9.914180120064493   0.09471863253894745              0.2301916479138043   0.19676108423799366   0.8144463451287597  0.29066281193714333  8.476040525047853  0.10363473695594466\n",
       "     2025-08-19 00:05:28  7 min 40.847 sec  20.0               0.22451130567101082  0.18544493968893289  0.8438584404968943  0.3711360094226586   10.725033170399188  0.08912950793160734              0.22873936843614345  0.1932464347756716    0.8213715464695849  0.3078055740381323   9.125719210568453  0.09541553193790371\n",
       "     2025-08-19 00:05:31  7 min 44.137 sec  25.0               0.22265612962031067  0.18170277409877308  0.8518788781006121  0.3918110844491655   11.228062377551268  0.08345952356449424              0.22779920866626852  0.19113367094214556   0.8263921985230316  0.31727768859709315  9.352351310168665  0.0945995103870695\n",
       "     2025-08-19 00:05:34  7 min 46.921 sec  30.0               0.22151662305909722  0.17951363627538763  0.8568036599797331  0.4034661972419746   11.38572824844968   0.0839912377423955               0.22725112059199426  0.19003248383636356   0.8289673297489586  0.32216770958840396  9.427895343368734  0.09826669157334854\n",
       "     2025-08-19 00:05:37  7 min 49.727 sec  35.0               0.22036802066855227  0.17745164221654722  0.8614106829758226  0.4159643601740355   11.618473105490194  0.08038685269312006              0.22677047082717208  0.18916079017100476   0.8309820999105894  0.32692413678138577  9.427895343368734  0.10249427310176673\n",
       "     2025-08-19 00:05:40  7 min 52.840 sec  40.0               0.21951988731206915  0.17588757374404038  0.8649048725672076  0.4244503888572998   11.843710063916498  0.08154584258319979              0.22641866799220722  0.18854327872293186   0.8322077574633528  0.33107807155304825  9.594092216408889  0.10181589374022987\n",
       "     2025-08-19 00:05:44  7 min 56.530 sec  45.0               0.2182543751992617   0.17353990222511348  0.8704686992358457  0.43843237231324383  12.106486515413854  0.07886031844043576              0.22592750495497313  0.18761992142176548   0.8344410000504058  0.33630751445298784  9.624309829688917  0.09980041882551886\n",
       "---  ---                  ---               ---                ---                  ---                  ---                 ---                  ---                 ---                              ---                  ---                   ---                 ---                  ---                ---\n",
       "     2025-08-19 00:06:00  8 min 12.851 sec  70.0               0.21350497555094966  0.16535971957694673  0.8882296461389136  0.4884175164546863   12.902323768520128  0.07081599749089715              0.22467745758862082  0.18511878145521213   0.8407313423532623  0.34783877595776935  9.624309829688917  0.08609518940548405\n",
       "     2025-08-19 00:06:03  8 min 16.146 sec  75.0               0.21293945195375066  0.16438459410665462  0.8902513120259284  0.4942141203524529   12.988664602583546  0.06954919458778674              0.22456036176643837  0.18490597206226803   0.8412181833475567  0.3492541835208288   9.63941863632893   0.08848426454828782\n",
       "     2025-08-19 00:06:07  8 min 19.735 sec  80.0               0.21222819391585004  0.16322898513072073  0.8926418611409487  0.5016928042283353   13.120052828332222  0.06821623369940752              0.22437853676963274  0.18459136814626062   0.8418998680704594  0.35117927751112266  9.745180282809029  0.09004748655530759\n",
       "     2025-08-19 00:06:11  8 min 23.480 sec  85.0               0.21160195207617633  0.16216477028414167  0.8947803517258732  0.5076238193216139   13.168854169324588  0.06672890417873438              0.22418946460985203  0.18424221489612275   0.8427118238730296  0.3534510556688195   9.805615509369085  0.08662609499277378\n",
       "     2025-08-19 00:06:14  8 min 27.238 sec  90.0               0.21071171139722192  0.1606418344510981   0.8978755368296257  0.5159527549971188   13.319012141608793  0.0677163733662653               0.22393403600440656  0.18380281417479805   0.8436170629402654  0.3558509405276627   9.79050670272907   0.08907415964527642\n",
       "     2025-08-19 00:06:18  8 min 31.013 sec  95.0               0.21010933929534897  0.15969633441949385  0.8996872387924207  0.5224614282573896   13.420368772900629  0.06551110719063791              0.2238837623491817   0.1836680807998935    0.8440378636350698  0.35624191196631827  9.850941929289126  0.09203346671516915\n",
       "     2025-08-19 00:06:22  8 min 35.154 sec  100.0              0.2094376527848529   0.1585640146470542   0.9020116716581592  0.529238627734538    13.499201708349835  0.0645040356371014               0.223837873776585    0.18360603022753805   0.8440899342228598  0.35687118219590536  9.850941929289126  0.08871039100213346\n",
       "     2025-08-19 00:06:26  8 min 38.828 sec  105.0              0.20911673909360745  0.15802742947610252  0.9030708244145191  0.5323204778319937   13.559264897263516  0.06654758229318279              0.22380251393330003  0.18352915003381004   0.844236128436437   0.35689584505733885  9.820724316009098  0.08861207515263536\n",
       "     2025-08-19 00:06:30  8 min 42.828 sec  110.0              0.20860579317385594  0.15717377531138638  0.9047738918994204  0.5373329840720519   13.656867579248248  0.06473681373341762              0.22371629605298096  0.18338687834361786   0.8445197769489183  0.35784243455856923  9.835833122649111  0.08716683216501332\n",
       "     2025-08-19 00:06:34  8 min 46.438 sec  115.0              0.2082739876491084   0.1566098442784407   0.9059744828287675  0.5406933348928543   13.649359680634037  0.06338180018328213              0.22370878091415272  0.18335358634857185   0.8446143124073078  0.35789994556673915  9.745180282809029  0.08682272669176998\n",
       "[24 rows x 16 columns]\n",
       "\n",
       "\n",
       "Variable Importances: \n",
       "variable                    relative_importance    scaled_importance       percentage\n",
       "--------------------------  ---------------------  ----------------------  ----------------------\n",
       "times_bought_by_user        25957.63671875         1.0                     0.23159351336363845\n",
       "num_orders                  16035.4169921875       0.6177533481160334      0.14306766828234296\n",
       "user_reorder_prop           13584.8310546875       0.5233462199151111      0.12120358977571995\n",
       "num_items                   12737.814453125        0.49071549121126595     0.11364652467158072\n",
       "avg_days_since_prior_order  12266.51171875         0.47255887936398777     0.10944157114308971\n",
       "last_order_number           10680.744140625        0.4114682802733721      0.09529338466620453\n",
       "product_reorder_prop        7650.60986328125       0.2947344531466911      0.06825858751355288\n",
       "product_total_orders        4036.314208984375      0.15549621303039582     0.03601191429045015\n",
       "avg_add_to_cart_order       3637.224365234375      0.14012155284564468     0.03245124272149158\n",
       "avg_user_product_position   3061.69580078125       0.1179497129863788      0.027316388430748236\n",
       "---                         ---                    ---                     ---\n",
       "aisle_id.57                 1.6125640869140625     6.212291605688655e-05   1.4387264390008747e-05\n",
       "aisle_id.129                1.3888421058654785     5.350418148283411e-05   1.2391221369255279e-05\n",
       "aisle_id.30                 1.1755201816558838     4.52861019049076e-05    1.048796744670131e-05\n",
       "aisle_id.85                 1.1435546875           4.405465335270584e-05   1.020277194997034e-05\n",
       "aisle_id.28                 0.9485785961151123     3.654333429475592e-05   8.46319917934446e-06\n",
       "aisle_id.6                  0.9269781112670898     3.5711190556785355e-05  8.270480087444309e-06\n",
       "aisle_id.49                 0.5939788818359375     2.2882625574572753e-05  5.299467651799949e-06\n",
       "aisle_id.67                 0.21893310546875       8.434246454747858e-06   1.9533167690298682e-06\n",
       "aisle_id.9                  0.14359235763549805    5.531796256774673e-06   1.2811281303182704e-06\n",
       "aisle_id.17                 0.11951184272766113    4.604111076157178e-06   1.066282260043683e-06\n",
       "[94 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml = H2OAutoML(max_models=20, seed=32021, exclude_algos = ['StackedEnsemble', 'DeepLearning'], nfolds=0)\n",
    "aml.train(x=features, y=target, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c163ab-1100-462d-a01a-069281b4a20d",
   "metadata": {},
   "source": [
    "#### Insights and best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e7189a5-c9c6-4719-879e-08a09bb4245f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id                                              auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
      "XGBoost_grid_1_AutoML_1_20250818_235405_model_3  0.844614   0.183354  0.3579                  0.308417  0.223709  0.0500456\n",
      "XGBoost_grid_1_AutoML_1_20250818_235405_model_2  0.844427   0.184076  0.353576                0.307824  0.224014  0.0501824\n",
      "XGBoost_grid_1_AutoML_1_20250818_235405_model_4  0.833544   0.18809   0.332579                0.315052  0.226253  0.0511903\n",
      "XGBoost_3_AutoML_1_20250818_235405               0.833281   0.188579  0.325574                0.312446  0.226773  0.0514258\n",
      "XGBoost_grid_1_AutoML_1_20250818_235405_model_1  0.833269   0.188456  0.330874                0.31309   0.226351  0.0512346\n",
      "XGBoost_grid_1_AutoML_1_20250818_235405_model_6  0.831525   0.189903  0.323041                0.30752   0.227193  0.0516165\n",
      "XGBoost_2_AutoML_1_20250818_235405               0.830977   0.189128  0.328011                0.312985  0.226665  0.0513769\n",
      "XGBoost_1_AutoML_1_20250818_235405               0.83056    0.190178  0.321788                0.313849  0.22719   0.0516151\n",
      "XGBoost_grid_1_AutoML_1_20250818_235405_model_5  0.823758   0.192604  0.30387                 0.323354  0.228982  0.0524329\n",
      "GBM_grid_1_AutoML_1_20250818_235405_model_3      0.819726   0.19389   0.298324                0.319618  0.229403  0.0526259\n",
      "[10 rows x 7 columns]\n",
      "\n",
      "Model Details\n",
      "=============\n",
      "H2OXGBoostEstimator : XGBoost\n",
      "Model Key: XGBoost_grid_1_AutoML_1_20250818_235405_model_3\n",
      "\n",
      "\n",
      "Model Summary: \n",
      "    number_of_trees\n",
      "--  -----------------\n",
      "    115\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.04337805393126096\n",
      "RMSE: 0.2082739876491084\n",
      "LogLoss: 0.1566098442784407\n",
      "Mean Per-Class Error: 0.2608528071470811\n",
      "AUC: 0.9059744828287675\n",
      "AUCPR: 0.5406933348928543\n",
      "Gini: 0.8119489656575349\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2344261389528239\n",
      "       0       1      Error    Rate\n",
      "-----  ------  -----  -------  ------------------\n",
      "0      368610  12871  0.0337   (12871.0/381481.0)\n",
      "1      12996   13637  0.488    (12996.0/26633.0)\n",
      "Total  381606  26508  0.0634   (25867.0/408114.0)\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "metric                       threshold    value     idx\n",
      "---------------------------  -----------  --------  -----\n",
      "max f1                       0.234426     0.513238  175\n",
      "max f2                       0.134774     0.581967  235\n",
      "max f0point5                 0.34656      0.575145  126\n",
      "max accuracy                 0.375018     0.947365  116\n",
      "max precision                0.908827     1         0\n",
      "max recall                   0.00285563   1         396\n",
      "max specificity              0.908827     1         0\n",
      "max absolute_mcc             0.24766      0.479683  169\n",
      "max min_per_class_accuracy   0.0837108    0.821462  278\n",
      "max mean_per_class_accuracy  0.0850156    0.822643  277\n",
      "max tns                      0.908827     381481    0\n",
      "max fns                      0.908827     26629     0\n",
      "max fps                      0.00134184   381481    399\n",
      "max tps                      0.00285563   26633     396\n",
      "max tnr                      0.908827     1         0\n",
      "max fnr                      0.908827     0.99985   0\n",
      "max fpr                      0.00134184   1         399\n",
      "max tpr                      0.00285563   1         396\n",
      "\n",
      "Gains/Lift Table: Avg response rate:  6.53 %, avg score:  6.53 %\n",
      "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
      "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
      "1        0.0100021                   0.527298           13.6494     13.6494            0.89074          0.628751    0.89074                     0.628751            0.136522        0.136522                   1264.94   1264.94            0.135353\n",
      "2        0.0200018                   0.426399           10.5737     12.1117            0.690027         0.47203     0.790396                    0.5504              0.105733        0.242256                   957.371   1111.17            0.237771\n",
      "3        0.0300014                   0.359294           8.33205     10.8519            0.543739         0.391002    0.708184                    0.497272            0.0833177       0.325574                   733.205   985.194            0.316207\n",
      "4        0.0400011                   0.311161           6.56727     9.78084            0.428571         0.334103    0.638285                    0.456482            0.0656704       0.391244                   556.727   878.084            0.375765\n",
      "5        0.0500007                   0.275009           5.32065     8.88884            0.347219         0.292258    0.580074                    0.423639            0.0532047       0.444449                   432.065   788.884            0.421986\n",
      "6        0.100001                    0.171227           3.64355     6.26619            0.237773         0.215434    0.408924                    0.319537            0.18218         0.626629                   264.355   526.619            0.563393\n",
      "7        0.15                        0.121335           2.10273     4.87842            0.137221         0.143915    0.318359                    0.260998            0.105133        0.731761                   110.273   387.842            0.622377\n",
      "8        0.2                         0.091254           1.39449     4.00742            0.0910026        0.105221    0.261519                    0.222053            0.0697255       0.801487                   39.449    300.742            0.643479\n",
      "9        0.3                         0.0570096          0.843323    2.95273            0.0550342        0.07216     0.192692                    0.172089            0.0843315       0.885818                   -15.6677  195.273            0.626718\n",
      "10       0.400001                    0.0382527          0.49712     2.33882            0.0324414        0.0468264   0.152629                    0.140773            0.0497128       0.935531                   -50.288   133.882            0.572918\n",
      "11       0.5                         0.0264959          0.284237    1.92791            0.0185489        0.0319762   0.125813                    0.119014            0.0284234       0.963954                   -71.5763  92.7909            0.496345\n",
      "12       0.599999                    0.0184749          0.168965    1.63475            0.0110264        0.0222756   0.106682                    0.102891            0.0168963       0.980851                   -83.1035  63.4754            0.407441\n",
      "13       0.7                         0.0126565          0.103254    1.41597            0.00673821       0.0154151   0.0924041                   0.0903943           0.0103255       0.991176                   -89.6746  41.5965            0.311504\n",
      "14       0.8                         0.0082304          0.0540688   1.24573            0.00352846       0.0103432   0.0812947                   0.080388            0.00540683      0.996583                   -94.5931  24.573             0.210308\n",
      "15       0.899999                    0.0047508          0.0296627   1.11061            0.00193575       0.00643065  0.0724771                   0.0721706           0.00296624      0.999549                   -97.0337  11.0612            0.106501\n",
      "16       1                           0.000421136        0.00450562  1                  0.000294031      0.00312866  0.0652587                   0.0652663           0.000450569     1                          -99.5494  0                  0\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.05004561865809638\n",
      "RMSE: 0.22370878091415272\n",
      "LogLoss: 0.18335358634857185\n",
      "Mean Per-Class Error: 0.3084172947113857\n",
      "AUC: 0.8446143124073078\n",
      "AUCPR: 0.35789994556673915\n",
      "Gini: 0.6892286248146156\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.20369456627446672\n",
      "       0      1     Error    Rate\n",
      "-----  -----  ----  -------  -----------------\n",
      "0      89993  5107  0.0537   (5107.0/95100.0)\n",
      "1      3724   2889  0.5631   (3724.0/6613.0)\n",
      "Total  93717  7996  0.0868   (8831.0/101713.0)\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "metric                       threshold    value     idx\n",
      "---------------------------  -----------  --------  -----\n",
      "max f1                       0.203695     0.39551   185\n",
      "max f2                       0.101618     0.487117  256\n",
      "max f0point5                 0.328253     0.421808  124\n",
      "max accuracy                 0.452417     0.938051  76\n",
      "max precision                0.850897     1         0\n",
      "max recall                   0.00126396   1         399\n",
      "max specificity              0.850897     1         0\n",
      "max absolute_mcc             0.211071     0.351163  181\n",
      "max min_per_class_accuracy   0.0660766    0.763496  291\n",
      "max mean_per_class_accuracy  0.0669451    0.76499   290\n",
      "max tns                      0.850897     95100     0\n",
      "max fns                      0.850897     6612      0\n",
      "max fps                      0.00126396   95100     399\n",
      "max tps                      0.00126396   6613      399\n",
      "max tnr                      0.850897     1         0\n",
      "max fnr                      0.850897     0.999849  0\n",
      "max fpr                      0.00126396   1         399\n",
      "max tpr                      0.00126396   1         399\n",
      "\n",
      "Gains/Lift Table: Avg response rate:  6.50 %, avg score:  6.41 %\n",
      "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
      "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
      "1        0.0100086                   0.497755           9.74518    9.74518            0.633595         0.600212    0.633595                    0.600212            0.0975352       0.0975352                  874.518   874.518            0.093613\n",
      "2        0.0200073                   0.402268           7.57696    8.6616             0.492625         0.445663    0.563145                    0.522975            0.0757599       0.173295                   657.696   766.16             0.163947\n",
      "3        0.030006                    0.343838           6.47293    7.93228            0.420846         0.371053    0.515727                    0.472351            0.064721        0.238016                   547.293   693.228            0.222474\n",
      "4        0.0400047                   0.300698           5.06643    7.21599            0.3294           0.322215    0.469157                    0.434826            0.0506578       0.288674                   406.643   621.599            0.265961\n",
      "5        0.0500034                   0.266446           4.76395    6.72568            0.309735         0.283712    0.437279                    0.404609            0.0476334       0.336307                   376.395   572.568            0.306213\n",
      "6        0.100007                    0.169461           3.21163    4.96866            0.208808         0.212175    0.323044                    0.308392            0.160593        0.4969                     221.163   396.866            0.424492\n",
      "7        0.15                        0.120366           2.18688    4.04152            0.142183         0.142756    0.262765                    0.253187            0.10933         0.60623                    118.688   304.152            0.487955\n",
      "8        0.200004                    0.0912312          1.53929    3.41593            0.100079         0.104875    0.222091                    0.216108            0.0769696       0.6832                     53.9286   241.593            0.516796\n",
      "9        0.300001                    0.0571934          1.07519    2.63571            0.0699046        0.0722682   0.171364                    0.168163            0.107515        0.790715                   7.51867   163.571            0.524837\n",
      "10       0.399998                    0.0383338          0.719816   2.15675            0.0467997        0.0468491   0.140224                    0.137835            0.0719794       0.862695                   -28.0184  115.675            0.494871\n",
      "11       0.500005                    0.026542           0.470253   1.81943            0.0305741        0.0320689   0.118292                    0.116681            0.0470286       0.909723                   -52.9747  81.9429            0.438209\n",
      "12       0.600002                    0.0184349          0.359908   1.57618            0.0233999        0.0222656   0.102478                    0.100945            0.0359897       0.945713                   -64.0092  57.6183            0.369751\n",
      "13       0.699999                    0.0126806          0.246491   1.38623            0.016026         0.0154306   0.0901277                   0.0887292           0.0246484       0.970361                   -75.3509  38.6233            0.289163\n",
      "14       0.799996                    0.00822754         0.151222   1.23186            0.00983187       0.0103422   0.0800909                   0.0789311           0.0151217       0.985483                   -84.8778  23.186             0.198385\n",
      "15       0.899993                    0.00473585         0.102831   1.10642            0.00668567       0.00643609  0.071935                    0.0708762           0.0102828       0.995766                   -89.7169  10.6415            0.102433\n",
      "16       1                           0.000610906        0.0423379  1                  0.00275265       0.00312774  0.0650163                   0.0641009           0.00423408      1                          -95.7662  0                  0\n",
      "\n",
      "Scoring History: \n",
      "     timestamp            duration          number_of_trees    training_rmse        training_logloss     training_auc        training_pr_auc      training_lift       training_classification_error    validation_rmse      validation_logloss    validation_auc      validation_pr_auc    validation_lift    validation_classification_error\n",
      "---  -------------------  ----------------  -----------------  -------------------  -------------------  ------------------  -------------------  ------------------  -------------------------------  -------------------  --------------------  ------------------  -------------------  -----------------  ---------------------------------\n",
      "     2025-08-19 00:05:17  7 min 29.831 sec  0.0                0.5                  0.693147180559752    0.5                 0.0652587267283161   1.0                 0.9347412732716839               0.5                  0.693147180560031     0.5                 0.06501627127309194  1.0                0.934983728726908\n",
      "     2025-08-19 00:05:19  7 min 31.419 sec  5.0                0.2510640033336335   0.25637946283726853  0.7795200661051312  0.257231594826234    7.648674931160105   0.10850154613661869              0.25155745955787867  0.2570447992421425    0.7750008292305106  0.23470290658905404  6.300372368885837  0.11710400833718404\n",
      "     2025-08-19 00:05:21  7 min 34.255 sec  10.0               0.23067966284377117  0.20294343809200885  0.8158274551358614  0.31029137300970316  9.013232286359276   0.0996780311383584               0.2326565370575483   0.20613201921195773   0.8040216725714557  0.27228113859276426  7.705491386407139  0.107390402406772\n",
      "     2025-08-19 00:05:25  7 min 37.612 sec  15.0               0.22692396902690806  0.1909913323583545   0.8321137246401109  0.34368302651781796  9.914180120064493   0.09471863253894745              0.2301916479138043   0.19676108423799366   0.8144463451287597  0.29066281193714333  8.476040525047853  0.10363473695594466\n",
      "     2025-08-19 00:05:28  7 min 40.847 sec  20.0               0.22451130567101082  0.18544493968893289  0.8438584404968943  0.3711360094226586   10.725033170399188  0.08912950793160734              0.22873936843614345  0.1932464347756716    0.8213715464695849  0.3078055740381323   9.125719210568453  0.09541553193790371\n",
      "     2025-08-19 00:05:31  7 min 44.137 sec  25.0               0.22265612962031067  0.18170277409877308  0.8518788781006121  0.3918110844491655   11.228062377551268  0.08345952356449424              0.22779920866626852  0.19113367094214556   0.8263921985230316  0.31727768859709315  9.352351310168665  0.0945995103870695\n",
      "     2025-08-19 00:05:34  7 min 46.921 sec  30.0               0.22151662305909722  0.17951363627538763  0.8568036599797331  0.4034661972419746   11.38572824844968   0.0839912377423955               0.22725112059199426  0.19003248383636356   0.8289673297489586  0.32216770958840396  9.427895343368734  0.09826669157334854\n",
      "     2025-08-19 00:05:37  7 min 49.727 sec  35.0               0.22036802066855227  0.17745164221654722  0.8614106829758226  0.4159643601740355   11.618473105490194  0.08038685269312006              0.22677047082717208  0.18916079017100476   0.8309820999105894  0.32692413678138577  9.427895343368734  0.10249427310176673\n",
      "     2025-08-19 00:05:40  7 min 52.840 sec  40.0               0.21951988731206915  0.17588757374404038  0.8649048725672076  0.4244503888572998   11.843710063916498  0.08154584258319979              0.22641866799220722  0.18854327872293186   0.8322077574633528  0.33107807155304825  9.594092216408889  0.10181589374022987\n",
      "     2025-08-19 00:05:44  7 min 56.530 sec  45.0               0.2182543751992617   0.17353990222511348  0.8704686992358457  0.43843237231324383  12.106486515413854  0.07886031844043576              0.22592750495497313  0.18761992142176548   0.8344410000504058  0.33630751445298784  9.624309829688917  0.09980041882551886\n",
      "---  ---                  ---               ---                ---                  ---                  ---                 ---                  ---                 ---                              ---                  ---                   ---                 ---                  ---                ---\n",
      "     2025-08-19 00:06:00  8 min 12.851 sec  70.0               0.21350497555094966  0.16535971957694673  0.8882296461389136  0.4884175164546863   12.902323768520128  0.07081599749089715              0.22467745758862082  0.18511878145521213   0.8407313423532623  0.34783877595776935  9.624309829688917  0.08609518940548405\n",
      "     2025-08-19 00:06:03  8 min 16.146 sec  75.0               0.21293945195375066  0.16438459410665462  0.8902513120259284  0.4942141203524529   12.988664602583546  0.06954919458778674              0.22456036176643837  0.18490597206226803   0.8412181833475567  0.3492541835208288   9.63941863632893   0.08848426454828782\n",
      "     2025-08-19 00:06:07  8 min 19.735 sec  80.0               0.21222819391585004  0.16322898513072073  0.8926418611409487  0.5016928042283353   13.120052828332222  0.06821623369940752              0.22437853676963274  0.18459136814626062   0.8418998680704594  0.35117927751112266  9.745180282809029  0.09004748655530759\n",
      "     2025-08-19 00:06:11  8 min 23.480 sec  85.0               0.21160195207617633  0.16216477028414167  0.8947803517258732  0.5076238193216139   13.168854169324588  0.06672890417873438              0.22418946460985203  0.18424221489612275   0.8427118238730296  0.3534510556688195   9.805615509369085  0.08662609499277378\n",
      "     2025-08-19 00:06:14  8 min 27.238 sec  90.0               0.21071171139722192  0.1606418344510981   0.8978755368296257  0.5159527549971188   13.319012141608793  0.0677163733662653               0.22393403600440656  0.18380281417479805   0.8436170629402654  0.3558509405276627   9.79050670272907   0.08907415964527642\n",
      "     2025-08-19 00:06:18  8 min 31.013 sec  95.0               0.21010933929534897  0.15969633441949385  0.8996872387924207  0.5224614282573896   13.420368772900629  0.06551110719063791              0.2238837623491817   0.1836680807998935    0.8440378636350698  0.35624191196631827  9.850941929289126  0.09203346671516915\n",
      "     2025-08-19 00:06:22  8 min 35.154 sec  100.0              0.2094376527848529   0.1585640146470542   0.9020116716581592  0.529238627734538    13.499201708349835  0.0645040356371014               0.223837873776585    0.18360603022753805   0.8440899342228598  0.35687118219590536  9.850941929289126  0.08871039100213346\n",
      "     2025-08-19 00:06:26  8 min 38.828 sec  105.0              0.20911673909360745  0.15802742947610252  0.9030708244145191  0.5323204778319937   13.559264897263516  0.06654758229318279              0.22380251393330003  0.18352915003381004   0.844236128436437   0.35689584505733885  9.820724316009098  0.08861207515263536\n",
      "     2025-08-19 00:06:30  8 min 42.828 sec  110.0              0.20860579317385594  0.15717377531138638  0.9047738918994204  0.5373329840720519   13.656867579248248  0.06473681373341762              0.22371629605298096  0.18338687834361786   0.8445197769489183  0.35784243455856923  9.835833122649111  0.08716683216501332\n",
      "     2025-08-19 00:06:34  8 min 46.438 sec  115.0              0.2082739876491084   0.1566098442784407   0.9059744828287675  0.5406933348928543   13.649359680634037  0.06338180018328213              0.22370878091415272  0.18335358634857185   0.8446143124073078  0.35789994556673915  9.745180282809029  0.08682272669176998\n",
      "[24 rows x 16 columns]\n",
      "\n",
      "\n",
      "Variable Importances: \n",
      "variable                    relative_importance    scaled_importance       percentage\n",
      "--------------------------  ---------------------  ----------------------  ----------------------\n",
      "times_bought_by_user        25957.63671875         1.0                     0.23159351336363845\n",
      "num_orders                  16035.4169921875       0.6177533481160334      0.14306766828234296\n",
      "user_reorder_prop           13584.8310546875       0.5233462199151111      0.12120358977571995\n",
      "num_items                   12737.814453125        0.49071549121126595     0.11364652467158072\n",
      "avg_days_since_prior_order  12266.51171875         0.47255887936398777     0.10944157114308971\n",
      "last_order_number           10680.744140625        0.4114682802733721      0.09529338466620453\n",
      "product_reorder_prop        7650.60986328125       0.2947344531466911      0.06825858751355288\n",
      "product_total_orders        4036.314208984375      0.15549621303039582     0.03601191429045015\n",
      "avg_add_to_cart_order       3637.224365234375      0.14012155284564468     0.03245124272149158\n",
      "avg_user_product_position   3061.69580078125       0.1179497129863788      0.027316388430748236\n",
      "---                         ---                    ---                     ---\n",
      "aisle_id.57                 1.6125640869140625     6.212291605688655e-05   1.4387264390008747e-05\n",
      "aisle_id.129                1.3888421058654785     5.350418148283411e-05   1.2391221369255279e-05\n",
      "aisle_id.30                 1.1755201816558838     4.52861019049076e-05    1.048796744670131e-05\n",
      "aisle_id.85                 1.1435546875           4.405465335270584e-05   1.020277194997034e-05\n",
      "aisle_id.28                 0.9485785961151123     3.654333429475592e-05   8.46319917934446e-06\n",
      "aisle_id.6                  0.9269781112670898     3.5711190556785355e-05  8.270480087444309e-06\n",
      "aisle_id.49                 0.5939788818359375     2.2882625574572753e-05  5.299467651799949e-06\n",
      "aisle_id.67                 0.21893310546875       8.434246454747858e-06   1.9533167690298682e-06\n",
      "aisle_id.9                  0.14359235763549805    5.531796256774673e-06   1.2811281303182704e-06\n",
      "aisle_id.17                 0.11951184272766113    4.604111076157178e-06   1.066282260043683e-06\n",
      "[94 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "print(lb.head(10))\n",
    "\n",
    "best_model = aml.leader\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345a682-9fb2-4d18-956e-96574823de5f",
   "metadata": {},
   "source": [
    "#### Predict on test set and log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60c24d4a-354c-491f-9365-5175ebe7abe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MLOps/lib/python3.13/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O AutoML results logged.\n"
     ]
    }
   ],
   "source": [
    "preds = best_model.predict(test_h2o)\n",
    "pred_labels = preds.as_data_frame()['predict']\n",
    "\n",
    "f1 = f1_score(y_test, pred_labels)\n",
    "accuracy = accuracy_score(y_test, pred_labels)\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_labels)\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title(\"Confusion Matrix for H2O AutoML's best model\")\n",
    "cm_path = 'confusion_matrix_aml.png'\n",
    "plt.savefig(cm_path)\n",
    "plt.close(fig)\n",
    "\n",
    "# Log automl's best model results with mlflow\n",
    "with mlflow.start_run(run_name='H2O_AutoML_Best'):\n",
    "    model_path = h2o.save_model(best_model, path='models', force=True)\n",
    "    mlflow.log_artifact(model_path, 'h2o_aml_model')\n",
    "\n",
    "    mlflow.log_param('model_type', 'H2O_AutoML_Leader')\n",
    "    mlflow.log_metric('f1_score', f1)\n",
    "    mlflow.log_metric('accuracy', accuracy)\n",
    "\n",
    "    mlflow.log_artifact(cm_path)\n",
    "\n",
    "print('H2O AutoML results logged.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLOps]",
   "language": "python",
   "name": "conda-env-MLOps-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
